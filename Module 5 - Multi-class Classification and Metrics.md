# Classification Metrics

![[Pasted image 20240211091929.png]]
![[Pasted image 20240211092249.png]]
![[Pasted image 20240211093554.png]]
Accuracy = Correct / Total

![[Pasted image 20240211093733.png]]
Precision = True Positive / (True Positive + False Positives)
- Of all of the sneaker predictions, 90% were correct

![[Pasted image 20240211093752.png]]
Recall = True Positive / (True Positive + False Negative)
- Of all of the sneakers, my model predicted half

 ![[Pasted image 20240211094824.png]]
 Moving the threshold will give you a tradeoff between precision and recall. 
 - Area Under the Curve (AUC)
 - Average Precision (AP)
 - Summarizes how well classifier does in many different situations

# Multiclass Classification